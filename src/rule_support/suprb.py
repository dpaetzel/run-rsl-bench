# An extension of suprb for if-then rule extraction.
#
# Copyright (C) 2023 David PÃ¤tzel
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.
from sklearn.base import BaseEstimator, RegressorMixin
import numpy as np  # type: ignore
import suprb  # type: ignore
from suprb import rule
import suprb.utils
from suprb.optimizer import solution
from suprb.optimizer import rule
from suprb.optimizer.rule.mutation import HalfnormIncrease
from sklearn.utils.validation import check_is_fitted  # type: ignore
from sklearn.utils import check_random_state

from .utils import clamp_transform


class SupRB(BaseEstimator, RegressorMixin):
    def __init__(
        self,
        n_iter=32,
        n_initial_rules=0,
        n_rules=4,
        random_state=None,
        verbose=10,
        rd_mutation_sigma=0.1,
        rd_delay=10,
        rd_init_fitness_alpha=0.01,
        # sc_selection=("RouletteWheel", {}),
        sc_selection=("Tournament", {"k": 5}),
        sc_crossover=("NPoint", {"n": 2}),
        # sc_crossover=("Uniform", {}),
        sc_mutation_rate=0.05,
    ):
        self.n_iter = n_iter
        self.n_initial_rules = n_initial_rules
        self.n_rules = n_rules
        self.random_state = random_state
        self.verbose = verbose
        self.rd_mutation_sigma = rd_mutation_sigma
        self.rd_delay = rd_delay
        self.rd_init_fitness_alpha = rd_init_fitness_alpha
        self.sc_selection = sc_selection
        self.sc_crossover = sc_crossover
        self.sc_mutation_rate = sc_mutation_rate

    def fit(self, X, y):
        rd = rule.es.ES1xLambda(
            operator="&",  # early stopping
            # n_iter=12, # default seems to be 10000?
            delay=self.rd_delay,
            init=rule.initialization.MeanInit(
                fitness=rule.fitness.VolumeWu(alpha=self.rd_init_fitness_alpha)
            ),
            mutation=HalfnormIncrease(sigma=self.rd_mutation_sigma),
        )

        sc = solution.ga.GeneticAlgorithm(
            # n_iter=, # default is 32
            # population_size # default is 32
            # elitist_ratio # default is 0.17
            # mutation=ga.mutation.BitFlips(), # default is BitFlips (actually
            # the only one implemented as of 2023-10-24)
            crossover=getattr(ga.crossover, self.sc_crossover[0])(
                **self.sc_crossover[1]
            ),
            selection=getattr(ga.selection, self.sc_selection[0])(
                **self.sc_selection[1]
            ),
        )

        self.suprb_ = suprb.SupRB(
            rule_generation=rd,
            solution_composition=sc,
            n_iter=self.n_iter,
            n_initial_rules=self.n_initial_rules,
            n_rules=self.n_rules,
            random_state=self.random_state,
            verbose=self.verbose,
            # This seems to be important esp. for tasks with many training data points.
            n_jobs=1,
        )

        self.suprb_.fit(X, y)

    def predict(self, X):
        return self.suprb_.predict(X)

    @property
    def rules_(self):
        return self.suprb_.elitist_.subpopulation

    def bounds_(self, X_min, X_max, transformer_X=None):
        rules = self.rules_
        lowers = [rule.match.bounds[:, 0] for rule in self.rules_]
        uppers = [rule.match.bounds[:, 1] for rule in self.rules_]

        return clamp_transform(lowers, uppers, X_min, X_max, transformer_X)
